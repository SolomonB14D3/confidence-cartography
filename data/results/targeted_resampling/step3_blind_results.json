{
  "model": "EleutherAI/pythia-6.9b",
  "K_values": [
    5,
    10
  ],
  "total_results": 186,
  "results": [
    {
      "pair_id": "france_capital",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.13417347688179385,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "france_capital",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.13417347688179385,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "japan_capital",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12025735852027235,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "japan_capital",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12025735852027235,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "australia_capital",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1301221172204047,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "australia_capital",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00019032989803235978,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1301221172204047,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "largest_ocean",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00028274665237404406,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2167883671562387,
      "best_branch_mean_conf": 0.2679785998213144,
      "best_branch_matches_truth": false,
      "best_branch_token": " study",
      "n_branches": 5
    },
    {
      "pair_id": "largest_ocean",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00028274665237404406,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2167883671562387,
      "best_branch_mean_conf": 0.38705053877250367,
      "best_branch_matches_truth": false,
      "best_branch_token": " city",
      "n_branches": 10
    },
    {
      "pair_id": "longest_river",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00011542207357706502,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2676321468324103,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "longest_river",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00011542207357706502,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2676321468324103,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "tallest_mountain",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 2.0380886780912988e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.3796259950078517,
      "best_branch_mean_conf": 0.6244416727739222,
      "best_branch_matches_truth": false,
      "best_branch_token": "ing",
      "n_branches": 5
    },
    {
      "pair_id": "tallest_mountain",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 2.0380886780912988e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.3796259950078517,
      "best_branch_mean_conf": 0.6244416727739222,
      "best_branch_matches_truth": false,
      "best_branch_token": "ing",
      "n_branches": 10
    },
    {
      "pair_id": "water_boiling",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.979279401595704e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3572950444537734,
      "best_branch_mean_conf": 0.6365765696939301,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "water_boiling",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.979279401595704e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3572950444537734,
      "best_branch_mean_conf": 0.6365765696939301,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 10
    },
    {
      "pair_id": "earth_orbit",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.593394002469722e-06,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.19709378792340432,
      "best_branch_mean_conf": 0.34634211802040227,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "earth_orbit",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.593394002469722e-06,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.19709378792340432,
      "best_branch_mean_conf": 0.4142063336427479,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 10
    },
    {
      "pair_id": "light_vs_sound",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.44320743958815e-06,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.24266132085422215,
      "best_branch_mean_conf": 0.3974621803923087,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "light_vs_sound",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.44320743958815e-06,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.24266132085422215,
      "best_branch_mean_conf": 0.4787313509732485,
      "best_branch_matches_truth": false,
      "best_branch_token": "\"",
      "n_branches": 10
    },
    {
      "pair_id": "diamond_composition",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.010224656201899052,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1136171989408987,
      "best_branch_mean_conf": 0.4599581758624741,
      "best_branch_matches_truth": false,
      "best_branch_token": " Fore",
      "n_branches": 5
    },
    {
      "pair_id": "diamond_composition",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.010224656201899052,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1136171989408987,
      "best_branch_mean_conf": 0.4599581758624741,
      "best_branch_matches_truth": false,
      "best_branch_token": " Fore",
      "n_branches": 10
    },
    {
      "pair_id": "gold_symbol",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 8.938022801885381e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2076531634219074,
      "best_branch_mean_conf": 0.7054405592304344,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "gold_symbol",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 8.938022801885381e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2076531634219074,
      "best_branch_mean_conf": 0.7054405592304344,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "chromosomes",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00015824138245079666,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.32661873612960335,
      "best_branch_mean_conf": 0.3315103085568318,
      "best_branch_matches_truth": false,
      "best_branch_token": " always",
      "n_branches": 5
    },
    {
      "pair_id": "chromosomes",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00015824138245079666,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.32661873612960335,
      "best_branch_mean_conf": 0.3315103085568318,
      "best_branch_matches_truth": false,
      "best_branch_token": " always",
      "n_branches": 10
    },
    {
      "pair_id": "speed_of_light",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00012025460455333814,
      "actual_divergence_point": 8,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.44578814711409603,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "speed_of_light",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00012025460455333814,
      "actual_divergence_point": 8,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.44578814711409603,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "abundant_element",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.008173974230885506,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38880383037030697,
      "best_branch_mean_conf": 0.335357595118694,
      "best_branch_matches_truth": false,
      "best_branch_token": "(",
      "n_branches": 5
    },
    {
      "pair_id": "abundant_element",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.008173974230885506,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38880383037030697,
      "best_branch_mean_conf": 0.5740466314018704,
      "best_branch_matches_truth": false,
      "best_branch_token": "man",
      "n_branches": 10
    },
    {
      "pair_id": "ww2_end",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 4,
      "blind_conf_at_position": 0.00015753059415146708,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2065758581253855,
      "best_branch_mean_conf": 0.30877186680833496,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 5
    },
    {
      "pair_id": "ww2_end",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 4,
      "blind_conf_at_position": 0.00015753059415146708,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2065758581253855,
      "best_branch_mean_conf": 0.3628239358464877,
      "best_branch_matches_truth": false,
      "best_branch_token": " a",
      "n_branches": 10
    },
    {
      "pair_id": "berlin_wall",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 4,
      "blind_conf_at_position": 1.0083043889608234e-05,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.1534880937233538,
      "best_branch_mean_conf": 0.3941347450718846,
      "best_branch_matches_truth": false,
      "best_branch_token": " November",
      "n_branches": 5
    },
    {
      "pair_id": "berlin_wall",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 4,
      "blind_conf_at_position": 1.0083043889608234e-05,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.1534880937233538,
      "best_branch_mean_conf": 0.3941347450718846,
      "best_branch_matches_truth": false,
      "best_branch_token": " November",
      "n_branches": 10
    },
    {
      "pair_id": "shakespeare",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.00015232253645081073,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17724669784123157,
      "best_branch_mean_conf": 0.48494642690223244,
      "best_branch_matches_truth": false,
      "best_branch_token": " T",
      "n_branches": 5
    },
    {
      "pair_id": "shakespeare",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.00015232253645081073,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17724669784123157,
      "best_branch_mean_conf": 0.48494642690223244,
      "best_branch_matches_truth": false,
      "best_branch_token": " T",
      "n_branches": 10
    },
    {
      "pair_id": "moon_landing",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 4.0379723941441625e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.11317309310106793,
      "best_branch_mean_conf": 0.2608733600160728,
      "best_branch_matches_truth": false,
      "best_branch_token": " thing",
      "n_branches": 5
    },
    {
      "pair_id": "moon_landing",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 4.0379723941441625e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.11317309310106793,
      "best_branch_mean_conf": 0.38411867641843855,
      "best_branch_matches_truth": false,
      "best_branch_token": " question",
      "n_branches": 10
    },
    {
      "pair_id": "roman_fall",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 4,
      "blind_conf_at_position": 3.2700219890102744e-05,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.11063785485540782,
      "best_branch_mean_conf": 0.3459491847276998,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 5
    },
    {
      "pair_id": "roman_fall",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 4,
      "blind_conf_at_position": 3.2700219890102744e-05,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.11063785485540782,
      "best_branch_mean_conf": 0.3459491847276998,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 10
    },
    {
      "pair_id": "declaration",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.7415403969353065e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2187793116217007,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "declaration",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.7415403969353065e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2187793116217007,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "human_lungs",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.002278780099004507,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08361723222769797,
      "best_branch_mean_conf": 0.4700874512616013,
      "best_branch_matches_truth": false,
      "best_branch_token": " types",
      "n_branches": 5
    },
    {
      "pair_id": "human_lungs",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.002278780099004507,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08361723222769797,
      "best_branch_mean_conf": 0.4700874512616013,
      "best_branch_matches_truth": false,
      "best_branch_token": " types",
      "n_branches": 10
    },
    {
      "pair_id": "heart_chambers",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00025047085364349186,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.12102072797715664,
      "best_branch_mean_conf": 0.47177669553918977,
      "best_branch_matches_truth": false,
      "best_branch_token": " its",
      "n_branches": 5
    },
    {
      "pair_id": "heart_chambers",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00025047085364349186,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.12102072797715664,
      "best_branch_mean_conf": 0.47177669553918977,
      "best_branch_matches_truth": false,
      "best_branch_token": " its",
      "n_branches": 10
    },
    {
      "pair_id": "dolphins",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.716023926855996e-05,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.03563554288302839,
      "best_branch_mean_conf": 0.47878022119402885,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 5
    },
    {
      "pair_id": "dolphins",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.716023926855996e-05,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.03563554288302839,
      "best_branch_mean_conf": 0.47878022119402885,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 10
    },
    {
      "pair_id": "spider_legs",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.7151286707958207e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1728041181043712,
      "best_branch_mean_conf": 0.5096259389749982,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "spider_legs",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.7151286707958207e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.1728041181043712,
      "best_branch_mean_conf": 0.5096259389749982,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "photosynthesis",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.0015464313328266144,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.19313704275659152,
      "best_branch_mean_conf": 0.3084619040959157,
      "best_branch_matches_truth": false,
      "best_branch_token": " seeds",
      "n_branches": 5
    },
    {
      "pair_id": "photosynthesis",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.0015464313328266144,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.19313704275659152,
      "best_branch_mean_conf": 0.3084619040959157,
      "best_branch_matches_truth": false,
      "best_branch_token": " seeds",
      "n_branches": 10
    },
    {
      "pair_id": "largest_organ",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00039507055771537125,
      "actual_divergence_point": 8,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.38268299810297324,
      "best_branch_mean_conf": 0.7346039546653629,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "largest_organ",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00039507055771537125,
      "actual_divergence_point": 8,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.38268299810297324,
      "best_branch_mean_conf": 0.7346039546653629,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "sqrt_144",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.75996343488805e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2233191663222637,
      "best_branch_mean_conf": 0.7054405592304344,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "sqrt_144",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.75996343488805e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2233191663222637,
      "best_branch_mean_conf": 0.7054405592304344,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "triangle_sides",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 7.717011612839997e-06,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12915288071671965,
      "best_branch_mean_conf": 0.5220352216539058,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "triangle_sides",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 7.717011612839997e-06,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12915288071671965,
      "best_branch_mean_conf": 0.6333624782379378,
      "best_branch_matches_truth": false,
      "best_branch_token": " and",
      "n_branches": 10
    },
    {
      "pair_id": "pi_value",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.0002475662622600794,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.07077214644024414,
      "best_branch_mean_conf": 0.33946278030998656,
      "best_branch_matches_truth": false,
      "best_branch_token": "\u2009",
      "n_branches": 5
    },
    {
      "pair_id": "pi_value",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.0002475662622600794,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.07077214644024414,
      "best_branch_mean_conf": 0.4006487635524536,
      "best_branch_matches_truth": false,
      "best_branch_token": " (",
      "n_branches": 10
    },
    {
      "pair_id": "circle_degrees",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00010299582208972424,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.12784016998401576,
      "best_branch_mean_conf": 0.35027398572613794,
      "best_branch_matches_truth": false,
      "best_branch_token": " several",
      "n_branches": 5
    },
    {
      "pair_id": "circle_degrees",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00010299582208972424,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.12784016998401576,
      "best_branch_mean_conf": 0.35027398572613794,
      "best_branch_matches_truth": false,
      "best_branch_token": " several",
      "n_branches": 10
    },
    {
      "pair_id": "mona_lisa",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00016695699014235288,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.34536684365739345,
      "best_branch_mean_conf": 0.7346039546653629,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "mona_lisa",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00016695699014235288,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.34536684365739345,
      "best_branch_mean_conf": 0.7346039546653629,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "great_wall",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0004776440327987075,
      "actual_divergence_point": 6,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.22358891430485528,
      "best_branch_mean_conf": 0.4324630605885485,
      "best_branch_matches_truth": true,
      "best_branch_token": " China",
      "n_branches": 5
    },
    {
      "pair_id": "great_wall",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0004776440327987075,
      "actual_divergence_point": 6,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.22358891430485528,
      "best_branch_mean_conf": 0.4324630605885485,
      "best_branch_matches_truth": true,
      "best_branch_token": " China",
      "n_branches": 10
    },
    {
      "pair_id": "coffee",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00012360607797745615,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.02728171259877854,
      "best_branch_mean_conf": 0.3762792812709589,
      "best_branch_matches_truth": false,
      "best_branch_token": " a",
      "n_branches": 5
    },
    {
      "pair_id": "coffee",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00012360607797745615,
      "actual_divergence_point": 2,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.02728171259877854,
      "best_branch_mean_conf": 0.37712377348977427,
      "best_branch_matches_truth": false,
      "best_branch_token": " polyp",
      "n_branches": 10
    },
    {
      "pair_id": "olympics",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.132674777996726e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.27877223282712293,
      "best_branch_mean_conf": 0.6962694784698005,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "olympics",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.132674777996726e-05,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.27877223282712293,
      "best_branch_mean_conf": 0.6962694784698005,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "us_currency",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 2.372583003307227e-05,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.24972957899869166,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "us_currency",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 2.372583003307227e-05,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.24972957899869166,
      "best_branch_mean_conf": 0.7157534303343189,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "statue_liberty",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 3.39249090757221e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.29282630086345307,
      "best_branch_mean_conf": 0.6962694784698005,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "statue_liberty",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 3.39249090757221e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.29282630086345307,
      "best_branch_mean_conf": 0.6962694784698005,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "largest_planet",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008457614458166063,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.34023254955536686,
      "best_branch_mean_conf": 0.5727242134511471,
      "best_branch_matches_truth": false,
      "best_branch_token": ")",
      "n_branches": 5
    },
    {
      "pair_id": "largest_planet",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008457614458166063,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.34023254955536686,
      "best_branch_mean_conf": 0.5727242134511471,
      "best_branch_matches_truth": false,
      "best_branch_token": ")",
      "n_branches": 10
    },
    {
      "pair_id": "moon_orbit",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00011437849752837792,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.016725377243346884,
      "best_branch_mean_conf": 0.4297140410223316,
      "best_branch_matches_truth": false,
      "best_branch_token": "light",
      "n_branches": 5
    },
    {
      "pair_id": "moon_orbit",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00011437849752837792,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.016725377243346884,
      "best_branch_mean_conf": 0.4297140410223316,
      "best_branch_matches_truth": false,
      "best_branch_token": "light",
      "n_branches": 10
    },
    {
      "pair_id": "num_planets",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00031601262162439525,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38583951587133924,
      "best_branch_mean_conf": 0.37028688421616185,
      "best_branch_matches_truth": false,
      "best_branch_token": " a",
      "n_branches": 5
    },
    {
      "pair_id": "num_planets",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00031601262162439525,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38583951587133924,
      "best_branch_mean_conf": 0.37028688421616185,
      "best_branch_matches_truth": false,
      "best_branch_token": " a",
      "n_branches": 10
    },
    {
      "pair_id": "sun_type",
      "regime": "R1",
      "source": "truth",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0007557155331596732,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.04643779343459755,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "sun_type",
      "regime": "R1",
      "source": "truth",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0007557155331596732,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.04643779343459755,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "heart_chambers",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00042061906424351037,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08788366030300192,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "heart_chambers",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00042061906424351037,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08788366030300192,
      "best_branch_mean_conf": 0.7422737026671794,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "largest_internal_organ",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 3.1278519600164145e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38427938191175187,
      "best_branch_mean_conf": 0.7511403014068492,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "largest_internal_organ",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 3.1278519600164145e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.38427938191175187,
      "best_branch_mean_conf": 0.7511403014068492,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "red_blood_cells",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00015749552403576672,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2902035336818598,
      "best_branch_mean_conf": 0.5204228892190648,
      "best_branch_matches_truth": false,
      "best_branch_token": " were",
      "n_branches": 5
    },
    {
      "pair_id": "red_blood_cells",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.00015749552403576672,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2902035336818598,
      "best_branch_mean_conf": 0.6564502583350986,
      "best_branch_matches_truth": false,
      "best_branch_token": "\n",
      "n_branches": 10
    },
    {
      "pair_id": "adult_bones",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 6,
      "blind_conf_at_position": 8.86041671037674e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08860299416755879,
      "best_branch_mean_conf": 0.25104309027665295,
      "best_branch_matches_truth": false,
      "best_branch_token": " it",
      "n_branches": 5
    },
    {
      "pair_id": "adult_bones",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 6,
      "blind_conf_at_position": 8.86041671037674e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.08860299416755879,
      "best_branch_mean_conf": 0.25104309027665295,
      "best_branch_matches_truth": false,
      "best_branch_token": " it",
      "n_branches": 10
    },
    {
      "pair_id": "insulin_source",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.007776728831231594,
      "actual_divergence_point": 5,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.15603130590170622,
      "best_branch_mean_conf": 0.5463537578471005,
      "best_branch_matches_truth": false,
      "best_branch_token": " islets",
      "n_branches": 5
    },
    {
      "pair_id": "insulin_source",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.007776728831231594,
      "actual_divergence_point": 5,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.15603130590170622,
      "best_branch_mean_conf": 0.5935058939503506,
      "best_branch_matches_truth": false,
      "best_branch_token": " Is",
      "n_branches": 10
    },
    {
      "pair_id": "longest_bone",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.0715280192671344e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4441084869282956,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "longest_bone",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.0715280192671344e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4441084869282956,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "aspirin_inflammation",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.5290875025093555e-05,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2886874699648211,
      "best_branch_mean_conf": 0.596640524720507,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "aspirin_inflammation",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.5290875025093555e-05,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2886874699648211,
      "best_branch_mean_conf": 0.6172698641062847,
      "best_branch_matches_truth": false,
      "best_branch_token": " and",
      "n_branches": 10
    },
    {
      "pair_id": "penicillin_use",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00011241136235184968,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.22737374951248057,
      "best_branch_mean_conf": 0.6759025148515191,
      "best_branch_matches_truth": false,
      "best_branch_token": "*",
      "n_branches": 5
    },
    {
      "pair_id": "penicillin_use",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00011241136235184968,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.22737374951248057,
      "best_branch_mean_conf": 0.6759025148515191,
      "best_branch_matches_truth": false,
      "best_branch_token": "*",
      "n_branches": 10
    },
    {
      "pair_id": "antihistamines",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 7,
      "blind_conf_at_position": 7.810884198988788e-06,
      "actual_divergence_point": 7,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.25990307409065283,
      "best_branch_mean_conf": 0.4734596160188731,
      "best_branch_matches_truth": false,
      "best_branch_token": " symptoms",
      "n_branches": 5
    },
    {
      "pair_id": "antihistamines",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 7,
      "blind_conf_at_position": 7.810884198988788e-06,
      "actual_divergence_point": 7,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.25990307409065283,
      "best_branch_mean_conf": 0.5181634901350157,
      "best_branch_matches_truth": false,
      "best_branch_token": " it",
      "n_branches": 10
    },
    {
      "pair_id": "type1_diabetes",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.00041840277845039964,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2710740456182975,
      "best_branch_mean_conf": 0.5346156076411717,
      "best_branch_matches_truth": false,
      "best_branch_token": " autoimmune",
      "n_branches": 5
    },
    {
      "pair_id": "type1_diabetes",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.00041840277845039964,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2710740456182975,
      "best_branch_mean_conf": 0.5352577240555547,
      "best_branch_matches_truth": false,
      "best_branch_token": " immune",
      "n_branches": 10
    },
    {
      "pair_id": "malaria_transmission",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 4,
      "blind_conf_at_position": 9.155531188298482e-06,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.18229746494931273,
      "best_branch_mean_conf": 0.5792253704741597,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 5
    },
    {
      "pair_id": "malaria_transmission",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 4,
      "blind_conf_at_position": 9.155531188298482e-06,
      "actual_divergence_point": 4,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.18229746494931273,
      "best_branch_mean_conf": 0.5792253704741597,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 10
    },
    {
      "pair_id": "hiv_target",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.057077239849605e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.32189782209788975,
      "best_branch_mean_conf": 0.49300010738273464,
      "best_branch_matches_truth": false,
      "best_branch_token": " and",
      "n_branches": 5
    },
    {
      "pair_id": "hiv_target",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 4.057077239849605e-05,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.32189782209788975,
      "best_branch_mean_conf": 0.49300010738273464,
      "best_branch_matches_truth": false,
      "best_branch_token": " and",
      "n_branches": 10
    },
    {
      "pair_id": "tuberculosis_cause",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0003320658579468727,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17427049570687814,
      "best_branch_mean_conf": 0.4357420501559425,
      "best_branch_matches_truth": false,
      "best_branch_token": " variety",
      "n_branches": 5
    },
    {
      "pair_id": "tuberculosis_cause",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0003320658579468727,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17427049570687814,
      "best_branch_mean_conf": 0.4586596604751642,
      "best_branch_matches_truth": false,
      "best_branch_token": " single",
      "n_branches": 10
    },
    {
      "pair_id": "scurvy_cause",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00014731062401551753,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2699201023286959,
      "best_branch_mean_conf": 0.43110311177692245,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "scurvy_cause",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00014731062401551753,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2699201023286959,
      "best_branch_mean_conf": 0.43110311177692245,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "rabies_transmission",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0010626696748659015,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.06360083795152605,
      "best_branch_mean_conf": 0.3543644762830809,
      "best_branch_matches_truth": false,
      "best_branch_token": " bodily",
      "n_branches": 5
    },
    {
      "pair_id": "rabies_transmission",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.0010626696748659015,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.06360083795152605,
      "best_branch_mean_conf": 0.3543644762830809,
      "best_branch_matches_truth": false,
      "best_branch_token": " bodily",
      "n_branches": 10
    },
    {
      "pair_id": "vaccine_mechanism",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0004731616354547441,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17738622093747836,
      "best_branch_mean_conf": 0.545744760948069,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "vaccine_mechanism",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0004731616354547441,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17738622093747836,
      "best_branch_mean_conf": 0.545744760948069,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "handwashing",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00015339007950387895,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.28166528987882583,
      "best_branch_mean_conf": 0.5645310087677311,
      "best_branch_matches_truth": false,
      "best_branch_token": "led",
      "n_branches": 5
    },
    {
      "pair_id": "handwashing",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00015339007950387895,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.28166528987882583,
      "best_branch_mean_conf": 0.5645310087677311,
      "best_branch_matches_truth": false,
      "best_branch_token": "led",
      "n_branches": 10
    },
    {
      "pair_id": "smoking_cancer",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00010173951159231365,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.33579659810857265,
      "best_branch_mean_conf": 0.5772503711856328,
      "best_branch_matches_truth": false,
      "best_branch_token": " status",
      "n_branches": 5
    },
    {
      "pair_id": "smoking_cancer",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.00010173951159231365,
      "actual_divergence_point": 1,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.33579659810857265,
      "best_branch_mean_conf": 0.5772503711856328,
      "best_branch_matches_truth": false,
      "best_branch_token": " status",
      "n_branches": 10
    },
    {
      "pair_id": "alcohol_liver",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 8.754831469559576e-06,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2572740168460541,
      "best_branch_mean_conf": 0.42615343399146305,
      "best_branch_matches_truth": false,
      "best_branch_token": " was",
      "n_branches": 5
    },
    {
      "pair_id": "alcohol_liver",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 8.754831469559576e-06,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2572740168460541,
      "best_branch_mean_conf": 0.543699109078651,
      "best_branch_matches_truth": false,
      "best_branch_token": "                        ",
      "n_branches": 10
    },
    {
      "pair_id": "vitamin_d_sunlight",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.001677503576502204,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.20302648812066765,
      "best_branch_mean_conf": 0.5501304365694523,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "vitamin_d_sunlight",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.001677503576502204,
      "actual_divergence_point": 4,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.20302648812066765,
      "best_branch_mean_conf": 0.5501304365694523,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "iron_anemia",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.0005281663034111261,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.05698287594132125,
      "best_branch_mean_conf": 0.36024830773073646,
      "best_branch_matches_truth": false,
      "best_branch_token": " many",
      "n_branches": 5
    },
    {
      "pair_id": "iron_anemia",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.0005281663034111261,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.05698287594132125,
      "best_branch_mean_conf": 0.36024830773073646,
      "best_branch_matches_truth": false,
      "best_branch_token": " many",
      "n_branches": 10
    },
    {
      "pair_id": "brain_energy",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00038970596506260335,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3088596298819704,
      "best_branch_mean_conf": 0.7511403014068492,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "brain_energy",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00038970596506260335,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3088596298819704,
      "best_branch_mean_conf": 0.7511403014068492,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "neuron_communication",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.0007228947360999882,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2027192179884878,
      "best_branch_mean_conf": 0.4268214896034736,
      "best_branch_matches_truth": false,
      "best_branch_token": " were",
      "n_branches": 5
    },
    {
      "pair_id": "neuron_communication",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.0007228947360999882,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2027192179884878,
      "best_branch_mean_conf": 0.5741268181456969,
      "best_branch_matches_truth": false,
      "best_branch_token": " of",
      "n_branches": 10
    },
    {
      "pair_id": "dna_structure",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.0014734157593920827,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23601065045555256,
      "best_branch_mean_conf": 0.5321517805568874,
      "best_branch_matches_truth": false,
      "best_branch_token": " de",
      "n_branches": 5
    },
    {
      "pair_id": "dna_structure",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 5,
      "blind_conf_at_position": 0.0014734157593920827,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23601065045555256,
      "best_branch_mean_conf": 0.5321517805568874,
      "best_branch_matches_truth": false,
      "best_branch_token": " de",
      "n_branches": 10
    },
    {
      "pair_id": "chromosome_count",
      "regime": "R1",
      "source": "medical",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.0010976572521030903,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2934240607137326,
      "best_branch_mean_conf": 0.43931930500548333,
      "best_branch_matches_truth": false,
      "best_branch_token": " two",
      "n_branches": 5
    },
    {
      "pair_id": "chromosome_count",
      "regime": "R1",
      "source": "medical",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.0010976572521030903,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2934240607137326,
      "best_branch_mean_conf": 0.4487230036840109,
      "best_branch_matches_truth": false,
      "best_branch_token": " three",
      "n_branches": 10
    },
    {
      "pair_id": "darth_vader",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.034318551421165466,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.09852287607888381,
      "best_branch_mean_conf": 0.41740253860397,
      "best_branch_matches_truth": false,
      "best_branch_token": " so",
      "n_branches": 5
    },
    {
      "pair_id": "darth_vader",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.034318551421165466,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.09852287607888381,
      "best_branch_mean_conf": 0.5114372275503618,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 10
    },
    {
      "pair_id": "snow_white",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.015428838320076466,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3218151925442119,
      "best_branch_mean_conf": 0.6332311211870267,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "snow_white",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.015428838320076466,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3218151925442119,
      "best_branch_mean_conf": 0.6332311211870267,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 10
    },
    {
      "pair_id": "jaws",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.025229940190911293,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.15438015466289862,
      "best_branch_mean_conf": 0.4275796327959089,
      "best_branch_matches_truth": false,
      "best_branch_token": ".\"",
      "n_branches": 5
    },
    {
      "pair_id": "jaws",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 6,
      "blind_conf_at_position": 0.025229940190911293,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.15438015466289862,
      "best_branch_mean_conf": 0.4275796327959089,
      "best_branch_matches_truth": false,
      "best_branch_token": ".\"",
      "n_branches": 10
    },
    {
      "pair_id": "forrest_gump",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.039131049066782,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.5368831228050921,
      "best_branch_mean_conf": 0.6658656344349895,
      "best_branch_matches_truth": false,
      "best_branch_token": " like",
      "n_branches": 5
    },
    {
      "pair_id": "forrest_gump",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.039131049066782,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.5368831228050921,
      "best_branch_mean_conf": 0.6658656344349895,
      "best_branch_matches_truth": false,
      "best_branch_token": " like",
      "n_branches": 10
    },
    {
      "pair_id": "silence_lambs",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.098479545675218e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.20883245657751104,
      "best_branch_mean_conf": 0.4187550984012584,
      "best_branch_matches_truth": false,
      "best_branch_token": " sir",
      "n_branches": 5
    },
    {
      "pair_id": "silence_lambs",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.098479545675218e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.20883245657751104,
      "best_branch_mean_conf": 0.512967279413715,
      "best_branch_matches_truth": false,
      "best_branch_token": " how",
      "n_branches": 10
    },
    {
      "pair_id": "money_evil",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.021515686064958572,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4170699098280498,
      "best_branch_mean_conf": 0.5077209823454419,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "money_evil",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.021515686064958572,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4170699098280498,
      "best_branch_mean_conf": 0.5077209823454419,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "curiosity_cat",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.005185984540730715,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.41477576261386273,
      "best_branch_mean_conf": 0.5476193968982747,
      "best_branch_matches_truth": false,
      "best_branch_token": ":",
      "n_branches": 5
    },
    {
      "pair_id": "curiosity_cat",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.005185984540730715,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.41477576261386273,
      "best_branch_mean_conf": 0.5476193968982747,
      "best_branch_matches_truth": false,
      "best_branch_token": ":",
      "n_branches": 10
    },
    {
      "pair_id": "play_it_sam",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0033781116362661123,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.15784773747436703,
      "best_branch_mean_conf": 0.38856353373690083,
      "best_branch_matches_truth": false,
      "best_branch_token": "list",
      "n_branches": 5
    },
    {
      "pair_id": "play_it_sam",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0033781116362661123,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.15784773747436703,
      "best_branch_mean_conf": 0.38856353373690083,
      "best_branch_matches_truth": false,
      "best_branch_token": "list",
      "n_branches": 10
    },
    {
      "pair_id": "berenstain",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0001590006286278367,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.224798561820838,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "berenstain",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0001590006286278367,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.224798561820838,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "curious_george",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.002430774737149477,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.10798119109434386,
      "best_branch_mean_conf": 0.4589101768630956,
      "best_branch_matches_truth": false,
      "best_branch_token": "\u201d",
      "n_branches": 5
    },
    {
      "pair_id": "curious_george",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.002430774737149477,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.10798119109434386,
      "best_branch_mean_conf": 0.5521523510105908,
      "best_branch_matches_truth": false,
      "best_branch_token": " (",
      "n_branches": 10
    },
    {
      "pair_id": "monopoly_man",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 3.486426794552244e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2898364199455601,
      "best_branch_mean_conf": 0.3865323241469533,
      "best_branch_matches_truth": false,
      "best_branch_token": "\n",
      "n_branches": 5
    },
    {
      "pair_id": "monopoly_man",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 3.486426794552244e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.2898364199455601,
      "best_branch_mean_conf": 0.42094830933846034,
      "best_branch_matches_truth": false,
      "best_branch_token": " is",
      "n_branches": 10
    },
    {
      "pair_id": "fruit_loom",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.586013114429079e-06,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.27022840826051225,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 5
    },
    {
      "pair_id": "fruit_loom",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 6.586013114429079e-06,
      "actual_divergence_point": 7,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.27022840826051225,
      "best_branch_mean_conf": 0.7657787565908888,
      "best_branch_matches_truth": false,
      "best_branch_token": " authors",
      "n_branches": 10
    },
    {
      "pair_id": "mandela_death",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008870559395290911,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2660790987535041,
      "best_branch_mean_conf": 0.4763742907671258,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 5
    },
    {
      "pair_id": "mandela_death",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008870559395290911,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2660790987535041,
      "best_branch_mean_conf": 0.4823157417704351,
      "best_branch_matches_truth": false,
      "best_branch_token": "1",
      "n_branches": 10
    },
    {
      "pair_id": "chartreuse",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00032004975946620107,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23922525497089903,
      "best_branch_mean_conf": 0.6170778460800648,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "chartreuse",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.00032004975946620107,
      "actual_divergence_point": 6,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23922525497089903,
      "best_branch_mean_conf": 0.7534793503582478,
      "best_branch_matches_truth": false,
      "best_branch_token": "\"",
      "n_branches": 10
    },
    {
      "pair_id": "oscar_mayer",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 5,
      "blind_resample_position": 4,
      "blind_conf_at_position": 0.00021059629216324538,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12454198951745639,
      "best_branch_mean_conf": 0.3661566336658628,
      "best_branch_matches_truth": false,
      "best_branch_token": " largest",
      "n_branches": 5
    },
    {
      "pair_id": "oscar_mayer",
      "regime": "R2",
      "source": "mandela_orig",
      "K": 10,
      "blind_resample_position": 4,
      "blind_conf_at_position": 0.00021059629216324538,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.12454198951745639,
      "best_branch_mean_conf": 0.4642899403678408,
      "best_branch_matches_truth": false,
      "best_branch_token": " second",
      "n_branches": 10
    },
    {
      "pair_id": "star_wars_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.034318551421165466,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.10131178572773933,
      "best_branch_mean_conf": 0.41740253860397,
      "best_branch_matches_truth": false,
      "best_branch_token": " so",
      "n_branches": 5
    },
    {
      "pair_id": "star_wars_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 0.034318551421165466,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.10131178572773933,
      "best_branch_mean_conf": 0.5114372275503618,
      "best_branch_matches_truth": false,
      "best_branch_token": " the",
      "n_branches": 10
    },
    {
      "pair_id": "we_are_champions_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 3,
      "blind_conf_at_position": 2.1466197722475044e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.11927904374369973,
      "best_branch_mean_conf": 0.6324437418962285,
      "best_branch_matches_truth": false,
      "best_branch_token": " (",
      "n_branches": 5
    },
    {
      "pair_id": "we_are_champions_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 3,
      "blind_conf_at_position": 2.1466197722475044e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.11927904374369973,
      "best_branch_mean_conf": 0.6324437418962285,
      "best_branch_matches_truth": false,
      "best_branch_token": " (",
      "n_branches": 10
    },
    {
      "pair_id": "risky_business_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 1.4366330560733331e-06,
      "actual_divergence_point": 9,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3296760814920724,
      "best_branch_mean_conf": 0.3815769534558058,
      "best_branch_matches_truth": false,
      "best_branch_token": " a",
      "n_branches": 5
    },
    {
      "pair_id": "risky_business_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 1.4366330560733331e-06,
      "actual_divergence_point": 9,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.3296760814920724,
      "best_branch_mean_conf": 0.6424508807249367,
      "best_branch_matches_truth": false,
      "best_branch_token": " base",
      "n_branches": 10
    },
    {
      "pair_id": "mandela_death_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008870559395290911,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2610000965243671,
      "best_branch_mean_conf": 0.4780228236069282,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 5
    },
    {
      "pair_id": "mandela_death_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0008870559395290911,
      "actual_divergence_point": 5,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.2610000965243671,
      "best_branch_mean_conf": 0.4780228236069282,
      "best_branch_matches_truth": false,
      "best_branch_token": "_",
      "n_branches": 10
    },
    {
      "pair_id": "silence_of_lambs_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.098479545675218e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23944402589889555,
      "best_branch_mean_conf": 0.4187550984012584,
      "best_branch_matches_truth": false,
      "best_branch_token": " sir",
      "n_branches": 5
    },
    {
      "pair_id": "silence_of_lambs_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 7.098479545675218e-05,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23944402589889555,
      "best_branch_mean_conf": 0.512967279413715,
      "best_branch_matches_truth": false,
      "best_branch_token": " how",
      "n_branches": 10
    },
    {
      "pair_id": "sherlock_elementary_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.9047215472674e-05,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.0712226263647608,
      "best_branch_mean_conf": 0.5366957863496448,
      "best_branch_matches_truth": false,
      "best_branch_token": "+",
      "n_branches": 5
    },
    {
      "pair_id": "sherlock_elementary_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 5.9047215472674e-05,
      "actual_divergence_point": null,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.0712226263647608,
      "best_branch_mean_conf": 0.5864820723337206,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 10
    },
    {
      "pair_id": "casablanca_play_it_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0033781116362661123,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17761311022331938,
      "best_branch_mean_conf": 0.38856353373690083,
      "best_branch_matches_truth": false,
      "best_branch_token": "list",
      "n_branches": 5
    },
    {
      "pair_id": "casablanca_play_it_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.0033781116362661123,
      "actual_divergence_point": 1,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.17761311022331938,
      "best_branch_mean_conf": 0.38856353373690083,
      "best_branch_matches_truth": false,
      "best_branch_token": "list",
      "n_branches": 10
    },
    {
      "pair_id": "star_trek_beam_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.002730931155383587,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.4508220204152167,
      "best_branch_mean_conf": 0.34914500592276454,
      "best_branch_matches_truth": false,
      "best_branch_token": "forming",
      "n_branches": 5
    },
    {
      "pair_id": "star_trek_beam_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.002730931155383587,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.4508220204152167,
      "best_branch_mean_conf": 0.5231570953813692,
      "best_branch_matches_truth": false,
      "best_branch_token": "Spot",
      "n_branches": 10
    },
    {
      "pair_id": "snow_white_mirror_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.015428838320076466,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.376337624900043,
      "best_branch_mean_conf": 0.6332311211870267,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 5
    },
    {
      "pair_id": "snow_white_mirror_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 2,
      "blind_conf_at_position": 0.015428838320076466,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.376337624900043,
      "best_branch_mean_conf": 0.6332311211870267,
      "best_branch_matches_truth": false,
      "best_branch_token": ",",
      "n_branches": 10
    },
    {
      "pair_id": "forrest_gump_chocolates_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.03893721103668213,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.5772160599008203,
      "best_branch_mean_conf": 0.6445935233854331,
      "best_branch_matches_truth": false,
      "best_branch_token": " like",
      "n_branches": 5
    },
    {
      "pair_id": "forrest_gump_chocolates_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.03893721103668213,
      "actual_divergence_point": 0,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.5772160599008203,
      "best_branch_mean_conf": 0.6445935233854331,
      "best_branch_matches_truth": false,
      "best_branch_token": " like",
      "n_branches": 10
    },
    {
      "pair_id": "wizard_of_oz_toto_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 8.050809265114367e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23462150321310302,
      "best_branch_mean_conf": 0.5737616509431973,
      "best_branch_matches_truth": false,
      "best_branch_token": "-",
      "n_branches": 5
    },
    {
      "pair_id": "wizard_of_oz_toto_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 8.050809265114367e-05,
      "actual_divergence_point": 3,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.23462150321310302,
      "best_branch_mean_conf": 0.6751153827644885,
      "best_branch_matches_truth": false,
      "best_branch_token": "1",
      "n_branches": 10
    },
    {
      "pair_id": "money_root_evil_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.021515686064958572,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4556239092101653,
      "best_branch_mean_conf": 0.4631860964000225,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 5
    },
    {
      "pair_id": "money_root_evil_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 0,
      "blind_conf_at_position": 0.021515686064958572,
      "actual_divergence_point": 0,
      "blind_hits_error": true,
      "greedy_mean_conf": 0.4556239092101653,
      "best_branch_mean_conf": 0.4631860964000225,
      "best_branch_matches_truth": false,
      "best_branch_token": ".",
      "n_branches": 10
    },
    {
      "pair_id": "apollo_13_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 5,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.010956695303320885,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.30448843650519847,
      "best_branch_mean_conf": 0.521762439670662,
      "best_branch_matches_truth": false,
      "best_branch_token": " for",
      "n_branches": 5
    },
    {
      "pair_id": "apollo_13_raw",
      "regime": "R2",
      "source": "mandela_exp",
      "K": 10,
      "blind_resample_position": 1,
      "blind_conf_at_position": 0.010956695303320885,
      "actual_divergence_point": 2,
      "blind_hits_error": false,
      "greedy_mean_conf": 0.30448843650519847,
      "best_branch_mean_conf": 0.6193952091465084,
      "best_branch_matches_truth": false,
      "best_branch_token": " ",
      "n_branches": 10
    }
  ]
}